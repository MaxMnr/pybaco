import multiprocessing as mp
import numpy as np
import cv2
import time
import logging
from pathlib import Path
from shapely.geometry import Polygon, Point
from typing import List, Tuple, Optional, Callable, Any

from .handler import VideoHandler
from .stabilization import stabilize_frame

logger = logging.getLogger(__name__)

class ProcessingPipeline:
    """Pipeline for processing video frames with optional averaging and stabilization."""
    
    def __init__(
        self, 
        handler: VideoHandler,
        output_dir: Optional[Path] = None,
        first_frame_index: int = 0,
        total_frames: Optional[int] = None,
        num_frames_to_average: int = 11,
        num_avg_workers: int = 20,
        num_flow_workers: int = 20,
        do_averaging: bool = True,
        do_stabilization: bool = True,
        callback: Optional[Callable[[int, int], None]] = None
    ):
        """Initialize processing pipeline.
        
        Args:
            handler: VideoHandler instance with path information
            output_dir: Directory to save output frames (defaults to handler.output_dir)
            first_frame_index: First frame to process
            total_frames: Total number of frames to process
            num_frames_to_average: Number of frames to average for noise reduction
            num_avg_workers: Number of workers for frame averaging
            num_flow_workers: Number of workers for optical flow processing
            do_averaging: Whether to perform frame averaging
            do_stabilization: Whether to perform frame stabilization
            callback: Optional callback function for progress updates
        """
        self.handler = handler
        self.output_dir = Path(output_dir) if output_dir else handler.output_dir
        self.first_frame_index = first_frame_index
        self.num_frames_to_average = num_frames_to_average if do_averaging else 1
        self.num_avg_workers = num_avg_workers if do_averaging else 1
        self.num_flow_workers = num_flow_workers
        self.callback = callback
        self.do_averaging = do_averaging
        self.do_stabilization = do_stabilization
        
        # Get video info if total_frames not specified
        if total_frames is None:
            video_info = handler.get_video_info()
            self.total_frames = video_info["frame_count"]
        else:
            self.total_frames = total_frames
            
        # Make sure output directory exists
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def frame_averaging_worker(
        self, 
        video_path: Path, 
        frame_indices: List[int], 
        num_frames_to_average: int, 
        queue: mp.Queue
    ) -> None:
        """Worker that reads frames in color, computes the average, and sends it to the queue.
        
        Args:
            video_path: Path to the video file
            frame_indices: List of frame indices to process
            num_frames_to_average: Number of frames to average
            queue: Queue to send results
        """
        cap = cv2.VideoCapture(str(video_path))

        if not cap.isOpened():
            logger.error(f"Failed to open video: {video_path}")
            queue.put(None)
            return

        frame_buffer = []
        half_window = num_frames_to_average // 2

        for frame_index in frame_indices:
            try:
                # Set position to first frame in averaging window
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index - half_window)
                
                frame_buffer.clear()
                for _ in range(num_frames_to_average):
                    ret, frame = cap.read()
                    if not ret:
                        logger.warning(f"Failed to read frame at index {frame_index}")
                        break
                    frame_buffer.append(frame.astype(np.float32))
                
                # Only process if we have all frames in the window
                if len(frame_buffer) == num_frames_to_average:
                    avg_frame = np.mean(frame_buffer, axis=0).astype(np.uint8)
                    queue.put((frame_index, avg_frame))
                else:
                    logger.warning(f"Incomplete frame buffer for frame {frame_index}")
            except Exception as e:
                logger.error(f"Error averaging frame {frame_index}: {str(e)}")

        # Signal that this worker is done
        queue.put(None)
        cap.release()

    def optical_flow_worker(
        self, 
        queue: mp.Queue, 
        output_dir: Path, 
        counter: mp.Value, 
        ref_img_gray: np.ndarray,
        contour_dir: Path
    ) -> None:
        """Stabilizes frames using optical flow and saves them.
        
        Args:
            queue: Queue to receive frames
            output_dir: Directory to save processed frames
            counter: Shared counter for progress tracking
            ref_img_gray: Reference grayscale image for stabilization
            contour_dir: Directory containing contour files
        """
        while True:
            data = queue.get()
            if data is None:
                break

            frame_index, avg_frame = data
            
            try:
                # Convert to grayscale for optical flow
                avg_frame_gray = cv2.cvtColor(avg_frame, cv2.COLOR_BGR2GRAY)
                
                # Load contour data
                contour_path = contour_dir / f"{frame_index:05d}_0.npy"
                if not contour_path.exists():
                    logger.warning(f"Contour file not found: {contour_path}")
                    continue
                
                contour = np.load(contour_path)
                polygon = Polygon(contour)

                # Stabilize the frame
                stabilized_frame = stabilize_frame(ref_img_gray, avg_frame_gray, avg_frame, polygon)

                # Save the processed frame
                output_path = output_dir / f"frame_{frame_index:05d}.png"
                cv2.imwrite(str(output_path), stabilized_frame)

                # Update shared counter
                with counter.get_lock():
                    counter.value += 1
                    
            except Exception as e:
                logger.error(f"Error processing frame {frame_index}: {str(e)}")

    def run(self) -> bool:
        """Run the processing pipeline.
        
        Returns:
            bool: True if processing completed successfully
        """
        if not self.handler.validate_paths():
            logger.error("Path validation failed.")
            return False
        
        logger.info(f"Processing video: {self.handler.video_path}")
        logger.info(f"Output directory: {self.output_dir}")
        logger.info(f"Mode: averaging={self.do_averaging}, stabilization={self.do_stabilization}")
        
        # Create queue for communication between workers
        queue = mp.Queue(maxsize=100)  # Limit queue size to prevent memory issues
        processed_frames = mp.Value('i', 0)
        
        # Calculate frame indices to process
        half_window = self.num_frames_to_average // 2
        frame_indices = list(range(
            half_window + self.first_frame_index, 
            min(self.total_frames, self.first_frame_index + self.total_frames) - half_window
        ))
        
        if not frame_indices:
            logger.error("No frames to process.")
            return False
        
        # Get reference frame for stabilization
        cap = cv2.VideoCapture(str(self.handler.video_path))
        cap.set(cv2.CAP_PROP_POS_FRAMES, self.first_frame_index)
        ret, ref_img = cap.read()
        cap.release()
        
        if not ret:
            logger.error("Failed to read reference frame.")
            return False
        
        ref_img_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)
        
        # Start frame averaging workers
        chunk_size = max(1, len(frame_indices) // self.num_avg_workers)
        avg_workers = []
        
        for i in range(self.num_avg_workers):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, len(frame_indices))
            chunk = frame_indices[start_idx:end_idx]
            
            if not chunk:  # Skip empty chunks
                continue
                
            worker = mp.Process(
                target=self.frame_averaging_worker, 
                args=(self.handler.video_path, chunk, self.num_frames_to_average, queue)
            )
            avg_workers.append(worker)
            worker.start()
            logger.debug(f"Started averaging worker {i} with {len(chunk)} frames")
        
        # Start optical flow workers
        flow_workers = []
        for i in range(self.num_flow_workers):
            print('aaaaaa')
            worker = mp.Process(
                target=self.optical_flow_worker, 
                args=(queue, self.output_dir, processed_frames, ref_img_gray, self.handler.contour_dir)
            )
            flow_workers.append(worker)
            worker.start()
            logger.debug(f"Started optical flow worker {i}")
        
        # Monitor progress
        start_time = time.time()
        total_frames_to_process = len(frame_indices)
        
        prev_processed = 0
        try:
            while any(worker.is_alive() for worker in avg_workers + flow_workers):
                time.sleep(1.0)  # Update every second
                
                with processed_frames.get_lock():
                    processed = processed_frames.value
                
                # Update progress if frames have been processed
                if processed != prev_processed:
                    prev_processed = processed
                    elapsed = time.time() - start_time
                    
                    if processed > 0:
                        estimated_total_time = (elapsed / processed) * total_frames_to_process
                        remaining_time = max(0, estimated_total_time - elapsed)
                        
                        progress_msg = (
                            f"Processed {processed}/{total_frames_to_process} frames - "
                            f"Elapsed: {elapsed:.1f}s - Remaining: {remaining_time:.1f}s"
                        )
                        
                        logger.info(progress_msg)
                        if self.callback:
                            self.callback(processed, total_frames_to_process)
                
            # Wait for workers to finish
            for worker in avg_workers:
                worker.join()
            
            # Signal optical flow workers to finish
            for _ in range(self.num_flow_workers):
                queue.put(None)
                
            for worker in flow_workers:
                worker.join()
            
        except KeyboardInterrupt:
            logger.warning("Processing interrupted by user.")
            # Terminate all workers
            for worker in avg_workers + flow_workers:
                if worker.is_alive():
                    worker.terminate()
            return False
        
        # Check if all frames were processed
        with processed_frames.get_lock():
            final_processed = processed_frames.value
            
        if final_processed < total_frames_to_process:
            logger.warning(f"Processing incomplete: {final_processed}/{total_frames_to_process} frames processed")
            return False
        
        logger.info("Processing complete.")
        return True